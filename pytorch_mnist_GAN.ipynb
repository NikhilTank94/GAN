{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "pytorch-mnist-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sCwBnq4-SLX"
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ73RNUu-SLe"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxpLQJAW-SLf"
      },
      "source": [
        "bs = 100 #paper 64, blog 256 -- ideal batch size ranges from 32 to 128\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) #mean 0.5, and std dev 0.5\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "print(len(train_dataset), len(test_dataset))\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle = True)\n",
        "print(len(train_loader), len(test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DENcbQB-SLg"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3) #if we are overfitting\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215Bmxv-SLg"
      },
      "source": [
        "print(train_dataset.data.size(0),train_dataset.data.size(1),train_dataset.data.size(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPeSB6F__zPo"
      },
      "source": [
        "z_dim = 100\r\n",
        "mnist_dim = train_dataset.data.size(1) * train_dataset.data.size(2)\r\n",
        "\r\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\r\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x8GtNvM-SLh"
      },
      "source": [
        "G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_GFfgSq-SLh"
      },
      "source": [
        "D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHHyBz6-SLi"
      },
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002 \n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3g3I_iY-SLi"
      },
      "source": [
        "def G_train(x):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7pl9sJ1-SLi"
      },
      "source": [
        "def D_train(x):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on fake\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sv2e7y_-SLj"
      },
      "source": [
        "n_epoch = 1000\n",
        "st_losses_g = [] #store losses for plotting\n",
        "st_losses_d = [] #store losses for plotting\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "    st_losses_g.append(torch.mean(torch.FloatTensor(G_losses))) #add this to other one\n",
        "    st_losses_d.append(torch.mean(torch.FloatTensor(D_losses))) #add this to other one\n",
        "    \n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % ((epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
        "    if epoch == 1 or epoch %10 == 0:\n",
        "        with torch.no_grad():\n",
        "            test_z = Variable(torch.randn(bs, z_dim).to(device)) #generate noise\n",
        "            generated = G(test_z)\n",
        "            filename = './output_bs100/GAN_bs100_%04d_epoch.png' %epoch\n",
        "            save_image(generated.view(100, 1, 28, 28), filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mWdzfxXca2b"
      },
      "source": [
        "[1/100]: loss_d: 0.784, loss_g: 4.191\r\n",
        "[2/100]: loss_d: 0.823, loss_g: 3.266\r\n",
        "[3/100]: loss_d: 0.729, loss_g: 2.635\r\n",
        "[4/100]: loss_d: 0.312, loss_g: 4.321\r\n",
        "[5/100]: loss_d: 0.539, loss_g: 3.450\r\n",
        "[6/100]: loss_d: 0.519, loss_g: 2.883\r\n",
        "[7/100]: loss_d: 0.551, loss_g: 2.844\r\n",
        "[8/100]: loss_d: 0.591, loss_g: 2.619\r\n",
        "[9/100]: loss_d: 0.616, loss_g: 2.493\r\n",
        "[10/100]: loss_d: 0.666, loss_g: 2.291\r\n",
        "[11/100]: loss_d: 0.690, loss_g: 2.180\r\n",
        "[12/100]: loss_d: 0.786, loss_g: 1.956\r\n",
        "[13/100]: loss_d: 0.774, loss_g: 2.015\r\n",
        "[14/100]: loss_d: 0.789, loss_g: 2.023\r\n",
        "[15/100]: loss_d: 0.804, loss_g: 1.935\r\n",
        "[16/100]: loss_d: 0.859, loss_g: 1.808\r\n",
        "[17/100]: loss_d: 0.848, loss_g: 1.821\r\n",
        "[18/100]: loss_d: 0.901, loss_g: 1.722\r\n",
        "[19/100]: loss_d: 0.908, loss_g: 1.629\r\n",
        "[20/100]: loss_d: 0.933, loss_g: 1.589\r\n",
        "[21/100]: loss_d: 0.965, loss_g: 1.515\r\n",
        "[22/100]: loss_d: 0.964, loss_g: 1.494\r\n",
        "[23/100]: loss_d: 0.959, loss_g: 1.526\r\n",
        "[24/100]: loss_d: 0.987, loss_g: 1.469\r\n",
        "[25/100]: loss_d: 0.975, loss_g: 1.455\r\n",
        "[26/100]: loss_d: 0.996, loss_g: 1.439\r\n",
        "[27/100]: loss_d: 1.026, loss_g: 1.348\r\n",
        "[28/100]: loss_d: 1.019, loss_g: 1.352\r\n",
        "[29/100]: loss_d: 1.026, loss_g: 1.385\r\n",
        "[30/100]: loss_d: 1.024, loss_g: 1.364\r\n",
        "[31/100]: loss_d: 1.059, loss_g: 1.305\r\n",
        "[32/100]: loss_d: 1.065, loss_g: 1.263\r\n",
        "[33/100]: loss_d: 1.065, loss_g: 1.278\r\n",
        "[34/100]: loss_d: 1.067, loss_g: 1.282\r\n",
        "[35/100]: loss_d: 1.074, loss_g: 1.270\r\n",
        "[36/100]: loss_d: 1.096, loss_g: 1.218\r\n",
        "[37/100]: loss_d: 1.112, loss_g: 1.182\r\n",
        "[38/100]: loss_d: 1.110, loss_g: 1.205\r\n",
        "[39/100]: loss_d: 1.128, loss_g: 1.152\r\n",
        "[40/100]: loss_d: 1.123, loss_g: 1.155\r\n",
        "[41/100]: loss_d: 1.131, loss_g: 1.144\r\n",
        "[42/100]: loss_d: 1.144, loss_g: 1.129\r\n",
        "[43/100]: loss_d: 1.145, loss_g: 1.118\r\n",
        "[44/100]: loss_d: 1.141, loss_g: 1.125\r\n",
        "[45/100]: loss_d: 1.143, loss_g: 1.144\r\n",
        "[46/100]: loss_d: 1.148, loss_g: 1.118\r\n",
        "[47/100]: loss_d: 1.156, loss_g: 1.120\r\n",
        "[48/100]: loss_d: 1.141, loss_g: 1.132\r\n",
        "[49/100]: loss_d: 1.164, loss_g: 1.093\r\n",
        "[50/100]: loss_d: 1.172, loss_g: 1.075\r\n",
        "[51/100]: loss_d: 1.165, loss_g: 1.099\r\n",
        "[52/100]: loss_d: 1.172, loss_g: 1.085\r\n",
        "[53/100]: loss_d: 1.161, loss_g: 1.097\r\n",
        "[54/100]: loss_d: 1.173, loss_g: 1.077\r\n",
        "[55/100]: loss_d: 1.180, loss_g: 1.067\r\n",
        "[56/100]: loss_d: 1.192, loss_g: 1.053\r\n",
        "[57/100]: loss_d: 1.188, loss_g: 1.044\r\n",
        "[58/100]: loss_d: 1.186, loss_g: 1.065\r\n",
        "[59/100]: loss_d: 1.200, loss_g: 1.026\r\n",
        "[60/100]: loss_d: 1.205, loss_g: 1.022\r\n",
        "[61/100]: loss_d: 1.204, loss_g: 1.055\r\n",
        "[62/100]: loss_d: 1.200, loss_g: 1.033\r\n",
        "[63/100]: loss_d: 1.212, loss_g: 0.999\r\n",
        "[64/100]: loss_d: 1.210, loss_g: 1.004\r\n",
        "[65/100]: loss_d: 1.209, loss_g: 1.019\r\n",
        "[66/100]: loss_d: 1.198, loss_g: 1.031\r\n",
        "[67/100]: loss_d: 1.210, loss_g: 1.012\r\n",
        "[68/100]: loss_d: 1.208, loss_g: 1.014\r\n",
        "[69/100]: loss_d: 1.214, loss_g: 1.005\r\n",
        "[70/100]: loss_d: 1.217, loss_g: 1.004\r\n",
        "[71/100]: loss_d: 1.217, loss_g: 0.994\r\n",
        "[72/100]: loss_d: 1.212, loss_g: 1.009\r\n",
        "[73/100]: loss_d: 1.229, loss_g: 0.991\r\n",
        "[74/100]: loss_d: 1.223, loss_g: 0.981\r\n",
        "[75/100]: loss_d: 1.223, loss_g: 0.979\r\n",
        "[76/100]: loss_d: 1.223, loss_g: 0.977\r\n",
        "[77/100]: loss_d: 1.223, loss_g: 0.996\r\n",
        "[78/100]: loss_d: 1.217, loss_g: 0.994\r\n",
        "[79/100]: loss_d: 1.229, loss_g: 0.986\r\n",
        "[80/100]: loss_d: 1.228, loss_g: 0.984\r\n",
        "[81/100]: loss_d: 1.224, loss_g: 0.980\r\n",
        "[82/100]: loss_d: 1.230, loss_g: 0.982\r\n",
        "[83/100]: loss_d: 1.235, loss_g: 0.969\r\n",
        "[84/100]: loss_d: 1.231, loss_g: 0.969\r\n",
        "[85/100]: loss_d: 1.241, loss_g: 0.955\r\n",
        "[86/100]: loss_d: 1.231, loss_g: 0.983\r\n",
        "[87/100]: loss_d: 1.231, loss_g: 0.973\r\n",
        "[88/100]: loss_d: 1.236, loss_g: 0.974\r\n",
        "[89/100]: loss_d: 1.230, loss_g: 0.973\r\n",
        "[90/100]: loss_d: 1.234, loss_g: 0.964\r\n",
        "[91/100]: loss_d: 1.245, loss_g: 0.944\r\n",
        "[92/100]: loss_d: 1.237, loss_g: 0.958\r\n",
        "[93/100]: loss_d: 1.236, loss_g: 0.968\r\n",
        "[94/100]: loss_d: 1.241, loss_g: 0.954\r\n",
        "[95/100]: loss_d: 1.238, loss_g: 0.961\r\n",
        "[96/100]: loss_d: 1.241, loss_g: 0.962\r\n",
        "[97/100]: loss_d: 1.251, loss_g: 0.930\r\n",
        "[98/100]: loss_d: 1.245, loss_g: 0.959\r\n",
        "[99/100]: loss_d: 1.243, loss_g: 0.954\r\n",
        "[100/100]: loss_d: 1.252, loss_g: 0.939"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO6ybypkcWNq"
      },
      "source": [
        "[101/200]: loss_d: 1.247, loss_g: 0.953\r\n",
        "[102/200]: loss_d: 1.250, loss_g: 0.936\r\n",
        "[103/200]: loss_d: 1.245, loss_g: 0.958\r\n",
        "[104/200]: loss_d: 1.242, loss_g: 0.962\r\n",
        "[105/200]: loss_d: 1.236, loss_g: 0.973\r\n",
        "[106/200]: loss_d: 1.237, loss_g: 0.965\r\n",
        "[107/200]: loss_d: 1.239, loss_g: 0.968\r\n",
        "[108/200]: loss_d: 1.241, loss_g: 0.950\r\n",
        "[109/200]: loss_d: 1.247, loss_g: 0.952\r\n",
        "[110/200]: loss_d: 1.244, loss_g: 0.963\r\n",
        "[111/200]: loss_d: 1.246, loss_g: 0.946\r\n",
        "[112/200]: loss_d: 1.253, loss_g: 0.929\r\n",
        "[113/200]: loss_d: 1.248, loss_g: 0.943\r\n",
        "[114/200]: loss_d: 1.243, loss_g: 0.952\r\n",
        "[115/200]: loss_d: 1.247, loss_g: 0.945\r\n",
        "[116/200]: loss_d: 1.251, loss_g: 0.947\r\n",
        "[117/200]: loss_d: 1.249, loss_g: 0.942\r\n",
        "[118/200]: loss_d: 1.244, loss_g: 0.943\r\n",
        "[119/200]: loss_d: 1.249, loss_g: 0.946\r\n",
        "[120/200]: loss_d: 1.250, loss_g: 0.951\r\n",
        "[121/200]: loss_d: 1.241, loss_g: 0.956\r\n",
        "[122/200]: loss_d: 1.254, loss_g: 0.939\r\n",
        "[123/200]: loss_d: 1.257, loss_g: 0.925\r\n",
        "[124/200]: loss_d: 1.251, loss_g: 0.945\r\n",
        "[125/200]: loss_d: 1.244, loss_g: 0.953\r\n",
        "[126/200]: loss_d: 1.252, loss_g: 0.937\r\n",
        "[127/200]: loss_d: 1.251, loss_g: 0.937\r\n",
        "[128/200]: loss_d: 1.246, loss_g: 0.959\r\n",
        "[129/200]: loss_d: 1.251, loss_g: 0.945\r\n",
        "[130/200]: loss_d: 1.249, loss_g: 0.934\r\n",
        "[131/200]: loss_d: 1.255, loss_g: 0.933\r\n",
        "[132/200]: loss_d: 1.249, loss_g: 0.937\r\n",
        "[133/200]: loss_d: 1.253, loss_g: 0.944\r\n",
        "[134/200]: loss_d: 1.256, loss_g: 0.928\r\n",
        "[135/200]: loss_d: 1.255, loss_g: 0.935\r\n",
        "[136/200]: loss_d: 1.244, loss_g: 0.953\r\n",
        "[137/200]: loss_d: 1.252, loss_g: 0.939\r\n",
        "[138/200]: loss_d: 1.249, loss_g: 0.941\r\n",
        "[139/200]: loss_d: 1.249, loss_g: 0.940\r\n",
        "[140/200]: loss_d: 1.255, loss_g: 0.934\r\n",
        "[141/200]: loss_d: 1.249, loss_g: 0.952\r\n",
        "[142/200]: loss_d: 1.245, loss_g: 0.949\r\n",
        "[143/200]: loss_d: 1.255, loss_g: 0.931\r\n",
        "[144/200]: loss_d: 1.254, loss_g: 0.944\r\n",
        "[145/200]: loss_d: 1.250, loss_g: 0.953\r\n",
        "[146/200]: loss_d: 1.254, loss_g: 0.926\r\n",
        "[147/200]: loss_d: 1.257, loss_g: 0.930\r\n",
        "[148/200]: loss_d: 1.260, loss_g: 0.923\r\n",
        "[149/200]: loss_d: 1.256, loss_g: 0.928\r\n",
        "[150/200]: loss_d: 1.260, loss_g: 0.927\r\n",
        "[151/200]: loss_d: 1.253, loss_g: 0.941\r\n",
        "[152/200]: loss_d: 1.252, loss_g: 0.932\r\n",
        "[153/200]: loss_d: 1.252, loss_g: 0.942\r\n",
        "[154/200]: loss_d: 1.251, loss_g: 0.943\r\n",
        "[155/200]: loss_d: 1.255, loss_g: 0.933\r\n",
        "[156/200]: loss_d: 1.261, loss_g: 0.922\r\n",
        "[157/200]: loss_d: 1.259, loss_g: 0.927\r\n",
        "[158/200]: loss_d: 1.253, loss_g: 0.933\r\n",
        "[159/200]: loss_d: 1.252, loss_g: 0.931\r\n",
        "[160/200]: loss_d: 1.255, loss_g: 0.933\r\n",
        "[161/200]: loss_d: 1.245, loss_g: 0.948\r\n",
        "[162/200]: loss_d: 1.254, loss_g: 0.938\r\n",
        "[163/200]: loss_d: 1.246, loss_g: 0.944\r\n",
        "[164/200]: loss_d: 1.259, loss_g: 0.935\r\n",
        "[165/200]: loss_d: 1.259, loss_g: 0.918\r\n",
        "[166/200]: loss_d: 1.253, loss_g: 0.934\r\n",
        "[167/200]: loss_d: 1.264, loss_g: 0.912\r\n",
        "[168/200]: loss_d: 1.250, loss_g: 0.938\r\n",
        "[169/200]: loss_d: 1.259, loss_g: 0.918\r\n",
        "[170/200]: loss_d: 1.256, loss_g: 0.940\r\n",
        "[171/200]: loss_d: 1.255, loss_g: 0.940\r\n",
        "[172/200]: loss_d: 1.261, loss_g: 0.918\r\n",
        "[173/200]: loss_d: 1.252, loss_g: 0.937\r\n",
        "[174/200]: loss_d: 1.251, loss_g: 0.937\r\n",
        "[175/200]: loss_d: 1.255, loss_g: 0.922\r\n",
        "[176/200]: loss_d: 1.259, loss_g: 0.924\r\n",
        "[177/200]: loss_d: 1.257, loss_g: 0.940\r\n",
        "[178/200]: loss_d: 1.261, loss_g: 0.923\r\n",
        "[179/200]: loss_d: 1.257, loss_g: 0.933\r\n",
        "[180/200]: loss_d: 1.255, loss_g: 0.935\r\n",
        "[181/200]: loss_d: 1.253, loss_g: 0.931\r\n",
        "[182/200]: loss_d: 1.260, loss_g: 0.929\r\n",
        "[183/200]: loss_d: 1.262, loss_g: 0.922\r\n",
        "[184/200]: loss_d: 1.255, loss_g: 0.946\r\n",
        "[185/200]: loss_d: 1.252, loss_g: 0.930\r\n",
        "[186/200]: loss_d: 1.259, loss_g: 0.926\r\n",
        "[187/200]: loss_d: 1.248, loss_g: 0.943\r\n",
        "[188/200]: loss_d: 1.253, loss_g: 0.933\r\n",
        "[189/200]: loss_d: 1.257, loss_g: 0.916\r\n",
        "[190/200]: loss_d: 1.252, loss_g: 0.943\r\n",
        "[191/200]: loss_d: 1.251, loss_g: 0.937\r\n",
        "[192/200]: loss_d: 1.253, loss_g: 0.926\r\n",
        "[193/200]: loss_d: 1.262, loss_g: 0.920\r\n",
        "[194/200]: loss_d: 1.258, loss_g: 0.930\r\n",
        "[195/200]: loss_d: 1.255, loss_g: 0.932\r\n",
        "[196/200]: loss_d: 1.257, loss_g: 0.921\r\n",
        "[197/200]: loss_d: 1.251, loss_g: 0.930\r\n",
        "[198/200]: loss_d: 1.257, loss_g: 0.925\r\n",
        "[199/200]: loss_d: 1.246, loss_g: 0.955\r\n",
        "[200/200]: loss_d: 1.247, loss_g: 0.949"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxGAM9RE-SLk"
      },
      "source": [
        "# plot and save the generator and discriminator loss\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(st_losses_g, label='Generator loss')\n",
        "plt.plot(st_losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('./output_bs100/GAN_loss_bs100_1000epoch.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Disy1u_bWz5"
      },
      "source": [
        "!zip -r /content/output.zip /content/output_bs100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp1WqZHkr8DO"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(\"/content/output.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}