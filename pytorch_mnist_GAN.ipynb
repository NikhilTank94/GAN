{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "pytorch-mnist-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sCwBnq4-SLX"
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import shuffle\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ73RNUu-SLe"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxpLQJAW-SLf"
      },
      "source": [
        "bs = 100 #paper 64, blog 256 -- ideal batch size ranges from 32 to 128\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) #mean 0.5, and std dev 0.5\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "print(len(train_dataset), len(test_dataset))\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle = True)\n",
        "print(len(train_loader), len(test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DENcbQB-SLg"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x): \n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3) #if we are overfitting\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g215Bmxv-SLg"
      },
      "source": [
        "print(train_dataset.data.size(0),train_dataset.data.size(1),train_dataset.data.size(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPeSB6F__zPo"
      },
      "source": [
        "z_dim = 100\r\n",
        "mnist_dim = train_dataset.data.size(1) * train_dataset.data.size(2)\r\n",
        "\r\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\r\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x8GtNvM-SLh"
      },
      "source": [
        "G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_GFfgSq-SLh"
      },
      "source": [
        "D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHHyBz6-SLi"
      },
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002 \n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3g3I_iY-SLi"
      },
      "source": [
        "def G_train(x):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7pl9sJ1-SLi"
      },
      "source": [
        "def D_train(x):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on fake\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YKzOOQSop3H"
      },
      "source": [
        "def calculate_fid(model, images1, images2):\r\n",
        "    # calculate activations\r\n",
        "    act1 = model.predict(images1)\r\n",
        "    act2 = model.predict(images2)\r\n",
        "    # calculate mean and covariance statistics\r\n",
        "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\r\n",
        "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\r\n",
        "    # calculate sum squared difference between means\r\n",
        "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\r\n",
        "    # calculate sqrt of product between cov\r\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\r\n",
        "    # check and correct imaginary numbers from sqrt\r\n",
        "    if iscomplexobj(covmean):\r\n",
        "      covmean = covmean.real\r\n",
        "    # calculate score\r\n",
        "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\r\n",
        "    return fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sv2e7y_-SLj"
      },
      "source": [
        "n_epoch = 1000\n",
        "st_losses_g = [] #store losses for plotting\n",
        "st_losses_d = [] #store losses for plotting\n",
        "st_fid = []\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses, = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "    st_losses_g.append(torch.mean(torch.FloatTensor(G_losses)))\n",
        "    st_losses_d.append(torch.mean(torch.FloatTensor(D_losses)))\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % ((epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
        "    \n",
        "    if epoch == 1 or epoch %10 == 0:\n",
        "        with torch.no_grad():\n",
        "            test_z = Variable(torch.randn(bs, z_dim).to(device)) #generate noise\n",
        "            generated = G(test_z)\n",
        "            #model = InceptionV3(include_top=False, pooling='avg', input_shape=(28, 28, 3))\n",
        "            #fid = calculate_fid(model, generated, Variable(generated.view(-1, mnist_dim)))\n",
        "            #st_fid.append(fid)\n",
        "            #print('fid: %.03f' %fid)\n",
        "            filename = './output_bs100/GAN_bs100_%04d_epoch.png' %epoch\n",
        "            save_image(generated.view(100, 1, 28, 28), filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxGAM9RE-SLk"
      },
      "source": [
        "# plot and save the generator and discriminator loss\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(st_losses_g, label='Generator loss')\n",
        "plt.plot(st_losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('./output_bs100/GAN_loss_bs100_1000epoch.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Disy1u_bWz5"
      },
      "source": [
        "!zip -r /content/output.zip /content/output_bs100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp1WqZHkr8DO"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(\"/content/output.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}